# YoutuGraphRAG æ¶æ„è®¾è®¡ä¸æ ¸å¿ƒæœºåˆ¶æ·±åº¦è§£æ

## ğŸ“‹ ç›®å½•
- [1. é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
- [2. æ ¸å¿ƒè®¾è®¡ç†å¿µ](#2-æ ¸å¿ƒè®¾è®¡ç†å¿µ)
- [3. ç³»ç»Ÿæ¶æ„](#3-ç³»ç»Ÿæ¶æ„)
- [4. æ ¸å¿ƒç»„ä»¶è¯¦è§£](#4-æ ¸å¿ƒç»„ä»¶è¯¦è§£)
- [5. æ•°æ®æµç¨‹](#5-æ•°æ®æµç¨‹)
- [6. å…³é”®æŠ€æœ¯æœºåˆ¶](#6-å…³é”®æŠ€æœ¯æœºåˆ¶)
- [7. æ¶æ„ä¼˜åŠ¿ä¸å±€é™](#7-æ¶æ„ä¼˜åŠ¿ä¸å±€é™)
- [8. ä¼˜åŒ–å»ºè®®](#8-ä¼˜åŒ–å»ºè®®)

## 1. é¡¹ç›®æ¦‚è¿°

YoutuGraphRAG æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆGraphRAGï¼‰ç³»ç»Ÿï¼Œé€šè¿‡æ„å»ºç»“æ„åŒ–çŸ¥è¯†å›¾è°±å¹¶ç»“åˆå¤šè·¯å¾„æ£€ç´¢æœºåˆ¶ï¼Œå®ç°æ™ºèƒ½é—®ç­”åŠŸèƒ½ã€‚ç³»ç»Ÿçš„æ ¸å¿ƒç‰¹è‰²æ˜¯ **IRCoTï¼ˆIterative Retrieval Chain-of-Thoughtï¼‰è¿­ä»£æ¨ç†æœºåˆ¶** å’Œ **Graph-First æ£€ç´¢ç­–ç•¥**ï¼Œèƒ½å¤Ÿåƒäººç±»ä¸“å®¶ä¸€æ ·é€æ­¥æ·±å…¥åˆ†æå¤æ‚é—®é¢˜ï¼Œå¹¶ä¼˜å…ˆåˆ©ç”¨å›¾è°±ç»“æ„è¿›è¡Œç²¾ç¡®æ¨ç†ã€‚

### 1.1 æ ¸å¿ƒèƒ½åŠ›
- **æ™ºèƒ½çŸ¥è¯†æŠ½å–**ï¼šä»æ–‡æ¡£ä¸­è‡ªåŠ¨æå–å®ä½“ã€å…³ç³»å’Œå±æ€§ï¼Œæ”¯æŒå±‚çº§å…³ç³»è‡ªåŠ¨æ¨å¯¼
- **ç»“æ„åŒ–å›¾è°±æ„å»º**ï¼šæ„å»ºå¤šå±‚æ¬¡çš„çŸ¥è¯†å›¾è°±ï¼Œè‡ªåŠ¨è¡¥å……ç¼ºå¤±çš„å±‚çº§å…³ç³»
- **Graph-First æ£€ç´¢**ï¼šä¼˜å…ˆåˆ©ç”¨å›¾è°±ç»“æ„è¿›è¡Œè·¯å¾„éå†å’Œå…³ç³»æ¨ç†
- **å¤šç»´åº¦æ£€ç´¢**ï¼šåŸºäºèŠ‚ç‚¹ã€å…³ç³»ã€ä¸‰å…ƒç»„ã€ç¤¾åŒºå’Œæ–‡æ¡£å—çš„äº”é‡ç´¢å¼•ï¼Œæ”¯æŒè§„åˆ™åŒ¹é…åå¤‡
- **æŸ¥è¯¢å¢å¼ºæœºåˆ¶**ï¼šæ™ºèƒ½æ‰©å±•åŒä¹‰è¯ã€æ¥¼å±‚è¡¨ç¤ºå’Œè®¾å¤‡ç±»å‹
- **è¿­ä»£æ¨ç†é—®ç­”**ï¼šé€šè¿‡IRCoTæœºåˆ¶å®ç°å¤æ‚é—®é¢˜çš„æ·±åº¦æ¨ç†
- **å¯è§†åŒ–å±•ç¤º**ï¼šæä¾›å›¾è°±å¯è§†åŒ–å’Œäº¤äº’ç•Œé¢

### 1.2 æŠ€æœ¯æ ˆ
- **åç«¯æ¡†æ¶**ï¼šFastAPI + WebSocket
- **å›¾è°±å­˜å‚¨**ï¼šNetworkXï¼ˆå†…å­˜å›¾ç»“æ„ï¼‰ + JSONï¼ˆæŒä¹…åŒ–æ ¼å¼ï¼‰
- **å‘é‡æ£€ç´¢**ï¼šFAISSå¤šé‡ç´¢å¼• + è§„åˆ™åŒ¹é…åå¤‡
- **NLPå¤„ç†**ï¼šspaCy + Sentence Transformers
- **LLMé›†æˆ**ï¼šæ”¯æŒDeepSeekã€OpenAIã€Ollamaç­‰API
- **Schemaç®¡ç†**ï¼šJSONæ ¼å¼çš„é¢†åŸŸæœ¬ä½“å®šä¹‰
- **æŸ¥è¯¢å¤„ç†**ï¼šQueryEnhancerï¼ˆåŒä¹‰è¯æ‰©å±•ï¼‰+ è§„åˆ™åŒ¹é…
- **å‰ç«¯ç•Œé¢**ï¼šHTML + JavaScript + ECharts

## 2. æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 2.1 åˆ†å±‚æ¶æ„è®¾è®¡
```
åº”ç”¨å±‚ï¼šWebæ¥å£ + å¯è§†åŒ–
æœåŠ¡å±‚ï¼šé—®ç­”æœåŠ¡ + å›¾è°±æ„å»ºæœåŠ¡
ç®—æ³•å±‚ï¼šIRCoTæ¨ç† + å¤šè·¯å¾„æ£€ç´¢
æ•°æ®å±‚ï¼šçŸ¥è¯†å›¾è°± + å‘é‡ç´¢å¼• + æ–‡æ¡£å—
```

### 2.2 æ¨¡å—åŒ–ç»„ä»¶
- **ç‹¬ç«‹çš„çŸ¥è¯†æŠ½å–æ¨¡å—**ï¼šæ”¯æŒä¸åŒé¢†åŸŸçš„schemaé€‚é…ï¼Œè‡ªåŠ¨å±‚çº§å…³ç³»æ¨å¯¼
- **Graph-First æ£€ç´¢ç­–ç•¥**ï¼šä¼˜å…ˆåˆ©ç”¨å›¾è°±ç»“æ„è¿›è¡Œè·¯å¾„éå†å’Œå…³ç³»æ¨ç†
- **å¤šå±‚æ¬¡æ£€ç´¢ç­–ç•¥**ï¼šæ”¯æŒè¯­ä¹‰æ£€ç´¢ + è§„åˆ™åŒ¹é… + å›¾è°±éå†çš„æ··åˆæ¨¡å¼
- **çµæ´»çš„æ¨ç†æœºåˆ¶**ï¼šæ”¯æŒNoAgentå’ŒAgentä¸¤ç§æ¨¡å¼
- **æŸ¥è¯¢å¢å¼ºç³»ç»Ÿ**ï¼šæ™ºèƒ½æ‰©å±•åŒä¹‰è¯ã€æ¥¼å±‚è¡¨ç¤ºå’Œè®¾å¤‡ç±»å‹
- **ç»Ÿä¸€çš„æç¤ºè¯ç®¡ç†**ï¼šé›†ä¸­é…ç½®ï¼Œåˆ†å¸ƒè°ƒç”¨

### 2.3 æ™ºèƒ½åŒ–ç‰¹æ€§
- **è‡ªé€‚åº”æŸ¥è¯¢ç”Ÿæˆ**ï¼šLLMæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€ç”Ÿæˆæ–°æŸ¥è¯¢
- **çŸ¥è¯†ç´¯ç§¯æœºåˆ¶**ï¼šè¿­ä»£è¿‡ç¨‹ä¸­æŒç»­ç§¯ç´¯ç›¸å…³çŸ¥è¯†
- **è‡ªæˆ‘è¯„ä¼°èƒ½åŠ›**ï¼šLLMè‡ªä¸»åˆ¤æ–­ä¿¡æ¯æ˜¯å¦å……åˆ†
- **æ™ºèƒ½åŒä¹‰è¯æ‰©å±•**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œæ‰©å±•æ¥¼å±‚ã€è®¾å¤‡ç±»å‹ç­‰åŒä¹‰è¡¨ç¤º
- **å±‚çº§å…³ç³»è‡ªåŠ¨æ¨å¯¼**ï¼šä»å±æ€§ä¿¡æ¯è‡ªåŠ¨æ¨å¯¼ç©ºé—´å±‚çº§å…³ç³»
- **è§„åˆ™åŒ¹é…åå¤‡**ï¼šå½“è¯­ä¹‰æ£€ç´¢å¤±æ•ˆæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°è§„åˆ™åŒ¹é…

## 3. ç³»ç»Ÿæ¶æ„

### 3.1 æ•´ä½“æ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Web Interface                           â”‚
â”‚                 (FastAPI + WebSocket)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Service Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Graph Builder   â”‚  â”‚ Q&A Service     â”‚                  â”‚
â”‚  â”‚ (KTBuilder)     â”‚  â”‚ (KTRetriever)   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Algorithm Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Entity Extract  â”‚  â”‚ Multi-Path      â”‚  â”‚ IRCoT       â”‚  â”‚
â”‚  â”‚ (LLM+Schema)    â”‚  â”‚ Retrieval       â”‚  â”‚ Reasoning   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     Data Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Knowledge Graph â”‚  â”‚ FAISS Indices   â”‚  â”‚ Document    â”‚  â”‚
â”‚  â”‚ (NetworkX+JSON) â”‚  â”‚ (5 Types)       â”‚  â”‚ Chunks      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ ¸å¿ƒæ–‡ä»¶ç»“æ„
```
youtu-graphrag/
â”œâ”€â”€ config/                     # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ base_config.yaml        # ä¸»é…ç½®æ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰æç¤ºè¯ï¼‰
â”‚   â””â”€â”€ config_loader.py        # é…ç½®åŠ è½½å™¨
â”œâ”€â”€ models/                     # æ ¸å¿ƒç®—æ³•æ¨¡å—
â”‚   â”œâ”€â”€ constructor/
â”‚   â”‚   â””â”€â”€ kt_gen.py          # çŸ¥è¯†å›¾è°±æ„å»ºå™¨ï¼ˆæ”¯æŒå±‚çº§å…³ç³»æ¨å¯¼ï¼‰
â”‚   â””â”€â”€ retriever/
â”‚       â”œâ”€â”€ enhanced_kt_retriever.py  # å¢å¼ºæ£€ç´¢å™¨ï¼ˆGraph-First + è§„åˆ™åŒ¹é…ï¼‰
â”‚       â”œâ”€â”€ faiss_filter.py    # FAISSå¤šé‡ç´¢å¼•ç®¡ç†
â”‚       â””â”€â”€ agentic_decomposer.py     # é—®é¢˜åˆ†è§£å™¨
â”œâ”€â”€ utils/                      # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ graph_processor.py     # å›¾è°±å¤„ç†
â”‚   â”œâ”€â”€ call_llm_api.py        # LLM APIè°ƒç”¨ï¼ˆæ”¯æŒDeepSeek/OpenAIï¼‰
â”‚   â”œâ”€â”€ query_enhancer.py      # æŸ¥è¯¢å¢å¼ºå™¨ï¼ˆåŒä¹‰è¯æ‰©å±•ï¼‰
â”‚   â””â”€â”€ logger.py              # æ—¥å¿—ç®¡ç†
â”œâ”€â”€ backend.py                  # FastAPIåç«¯æœåŠ¡ï¼ˆIRCoT + Graph-Firstï¼‰
â”œâ”€â”€ main.py                     # æ‰¹å¤„ç†å…¥å£
â””â”€â”€ frontend/                   # Webå‰ç«¯
    â””â”€â”€ index.html
```

## 4. æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 4.1 æç¤ºè¯ç®¡ç†ç³»ç»Ÿ

#### 4.1.1 è®¾è®¡æ¶æ„
æç¤ºè¯é‡‡ç”¨**é›†ä¸­é…ç½®ã€åˆ†å¸ƒè°ƒç”¨**çš„ç®¡ç†æ¨¡å¼ï¼š

```yaml
# config/base_config.yaml
prompts:
  construction:          # å›¾è°±æ„å»ºæç¤ºè¯
    general: "You are an expert information extractor..."
    general_agent: "...with schema evolution capability..."
  
  decomposition:         # é—®é¢˜åˆ†è§£æç¤ºè¯
    general: "You are a professional question decomposition expert..."
  
  retrieval:            # æ£€ç´¢å›ç­”æç¤ºè¯
    general: "You are an expert knowledge assistant..."
    ircot: "You are an expert using iterative retrieval with CoT..."
```

#### 4.1.2 æç¤ºè¯ç±»å‹ä¸ä½œç”¨

| æç¤ºè¯ç±»å‹ | æ–‡ä»¶ä½ç½® | æ ¸å¿ƒä½œç”¨ | å…³é”®ç‰¹æ€§ |
|-----------|----------|----------|----------|
| **construction** | `base_config.yaml` | çŸ¥è¯†æŠ½å– | ç»“æ„åŒ–è¾“å‡ºã€Schemaå¼•å¯¼ |
| **decomposition** | `base_config.yaml` | é—®é¢˜åˆ†è§£ | å¤šè·³æ¨ç†ã€ç±»å‹è¯†åˆ« |
| **retrieval.ircot** | `base_config.yaml` | IRCoTæ¨ç† | æ¡ä»¶åˆ†æ”¯ã€è¿­ä»£æ§åˆ¶ |
| **retrieval.general** | `base_config.yaml` | æœ€ç»ˆå›ç­” | ä¸¥æ ¼çº¦æŸã€è´¨é‡æ§åˆ¶ |

#### 4.1.3 æç¤ºè¯çš„æ™ºèƒ½è®¾è®¡ç‰¹ç‚¹

1. **æ¡ä»¶åˆ†æ”¯é€»è¾‘**
```yaml
ircot: |
  Instructions:
  3. If you have enough information â†’ "So the answer is:"
  4. If you need more information â†’ "The new query is:"
```

2. **ä¸Šä¸‹æ–‡ç´¯ç§¯æœºåˆ¶**
```yaml
Current Question: {current_query}
Available Knowledge Context: {context}
Previous Thoughts: {previous_thoughts}
```

3. **è¾“å‡ºæ ¼å¼ä¸¥æ ¼æ§åˆ¶**
```yaml
construction: |
  Output Format: Return only JSON with:
  - Attributes: Map each entity to descriptive features
  - Triples: List relations in [entity1, relation, entity2] format
  - Entity_types: Map each entity to schema type
```

### 4.2 IRCoTï¼ˆè¿­ä»£æ£€ç´¢é“¾å¼æ€è€ƒï¼‰æœºåˆ¶

#### 4.2.1 æ ¸å¿ƒæ€æƒ³
IRCoTæ¨¡æ‹Ÿäººç±»ä¸“å®¶è§£å†³å¤æ‚é—®é¢˜çš„æ€ç»´è¿‡ç¨‹ï¼š
1. **åˆå§‹åˆ†æ** â†’ å‘ç°ä¿¡æ¯ä¸è¶³
2. **ç”Ÿæˆæ–°æŸ¥è¯¢** â†’ è·å–è¡¥å……ä¿¡æ¯
3. **æ•´åˆæ€è€ƒ** â†’ åˆ¤æ–­æ˜¯å¦è¶³å¤Ÿå›ç­”
4. **è¿­ä»£æ·±å…¥** â†’ ç›´åˆ°è·å¾—å®Œæ•´ç­”æ¡ˆ

#### 4.2.2 å®ç°ä½ç½®
- **ä¸»å®ç°**ï¼š`backend.py` (ç¬¬730-790è¡Œ) - Web APIç‰ˆæœ¬
- **æ‰¹å¤„ç†ç‰ˆ**ï¼š`main.py` (ç¬¬370-515è¡Œ) - æ‰¹é‡å¤„ç†ç‰ˆæœ¬
- **é…ç½®æ¨¡æ¿**ï¼š`base_config.yaml` (ç¬¬237-273è¡Œ) - æç¤ºè¯æ¨¡æ¿

#### 4.2.3 å·¥ä½œæµç¨‹
```python
# é˜¶æ®µ1ï¼šåˆå§‹åŒ–
thoughts = []  # å­˜å‚¨æ¨ç†æ€è·¯
all_triples = set()  # ç´¯ç§¯ä¸‰å…ƒç»„
all_chunk_ids = set()  # ç´¯ç§¯æ–‡æ¡£å—
current_query = question

# é˜¶æ®µ2ï¼šIRCoTè¿­ä»£å¾ªç¯
for step in range(1, max_steps + 1):
    # 1. æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
    context = build_context(all_triples, all_chunk_ids)
    
    # 2. IRCoTæ¨ç†
    reasoning = llm_call(ircot_prompt.format(
        question=question,
        current_query=current_query,
        context=context,
        thoughts=thoughts
    ))
    
    # 3. è§£ææ¨ç†ç»“æœ
    if "So the answer is:" in reasoning:
        final_answer = extract_answer(reasoning)
        break
    elif "The new query is:" in reasoning:
        new_query = extract_new_query(reasoning)
        current_query = new_query
        
        # 4. åŸºäºæ–°æŸ¥è¯¢æ£€ç´¢
        new_results = retriever.search(current_query)
        all_triples.update(new_results['triples'])
        all_chunk_ids.update(new_results['chunk_ids'])
    
    thoughts.append(reasoning)
```

#### 4.2.4 IRCoTçš„ä¼˜åŠ¿
- **åŠ¨æ€æŸ¥è¯¢**ï¼šæ ¹æ®éœ€è¦ç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢
- **æ·±åº¦æ¨ç†**ï¼šæ¯æ¬¡è¿­ä»£éƒ½åœ¨å‰ä¸€æ¬¡åŸºç¡€ä¸Šæ·±å…¥
- **è‡ªæˆ‘è¯„ä¼°**ï¼šLLMè‡ªä¸»åˆ¤æ–­ä¿¡æ¯å……åˆ†æ€§
- **çŸ¥è¯†æ•´åˆ**ï¼šå°†å¤šæ¬¡æ£€ç´¢ç»“æœæœ‰æœºæ•´åˆ

### 4.3 çŸ¥è¯†å›¾è°±æ„å»ºæœºåˆ¶

#### 4.3.1 æ„å»ºæµç¨‹
```
æ–‡æ¡£è¾“å…¥ â†’ SchemaåŠ è½½ â†’ åˆ†å—å¤„ç† â†’ å®ä½“æŠ½å– â†’ å…³ç³»è¯†åˆ« â†’ å›¾è°±åˆå¹¶ â†’ JSONè¾“å‡º
```

#### 4.3.2 Schemaç³»ç»Ÿè¯¦è§£

**Schemaæ˜¯çŸ¥è¯†æŠ½å–çš„æ ¸å¿ƒæŒ‡å¯¼æ¡†æ¶**ï¼Œå®šä¹‰äº†ç³»ç»Ÿèƒ½å¤Ÿè¯†åˆ«çš„å®ä½“ç±»å‹ã€å…³ç³»ç±»å‹å’Œå±æ€§ç±»å‹ã€‚

1. **Schemaæ–‡ä»¶ç»“æ„**ï¼ˆ`schemas/demo.json`ï¼‰
```json
{
  "Nodes": [
    "person", "location", "organization", "event", 
    "object", "concept", "time_period", "creative_work"
  ],
  "Relations": [
    "is_a", "part_of", "located_in", "created_by",
    "used_by", "participates_in", "related_to"
  ],
  "Attributes": [
    "name", "date", "size", "type", "description",
    "status", "quantity", "value", "position"
  ]
}
```

2. **Schemaçš„ä½œç”¨æœºåˆ¶**
```python
# Schemaåœ¨æç¤ºè¯ä¸­çš„ä½¿ç”¨
def _get_construction_prompt(self, chunk: str) -> str:
    schema_text = json.dumps(self.schema, ensure_ascii=False, indent=2)
    return self.config.get_prompt_formatted(
        "construction", prompt_type, 
        schema=schema_text,  # â† Schemaæ³¨å…¥æç¤ºè¯
        chunk=chunk
    )
```

3. **Schemaå¼•å¯¼çš„æŠ½å–è¿‡ç¨‹**
- **çº¦æŸæŠ½å–èŒƒå›´**ï¼šåªæå–Schemaä¸­å®šä¹‰çš„å®ä½“å’Œå…³ç³»ç±»å‹
- **æé«˜æŠ½å–è´¨é‡**ï¼šä¸ºLLMæä¾›æ˜ç¡®çš„æŠ½å–ç›®æ ‡
- **ä¿è¯ä¸€è‡´æ€§**ï¼šç¡®ä¿ä¸åŒæ–‡æ¡£çš„æŠ½å–ç»“æœæ ¼å¼ç»Ÿä¸€
- **æ”¯æŒé¢†åŸŸé€‚é…**ï¼šä¸åŒé¢†åŸŸä½¿ç”¨ä¸åŒçš„Schemaæ–‡ä»¶

#### 4.3.3 NetworkXå›¾ç»“æ„è¯¦è§£

**NetworkXä¸æ˜¯ç”¨äºå›¾æ•°æ®æ£€ç´¢æŸ¥è¯¢ï¼Œè€Œæ˜¯ç”¨äºå†…å­˜ä¸­çš„å›¾ç»“æ„å­˜å‚¨å’Œæ“ä½œ**ã€‚

1. **NetworkXçš„å®šä½**
```python
# åœ¨KTBuilderä¸­åˆ›å»ºå›¾ç»“æ„
self.graph = nx.MultiDiGraph()  # å¤šé‡æœ‰å‘å›¾

# å›¾çš„åŸºæœ¬æ“ä½œ
self.graph.add_node(node_id, label="entity", properties={"name": "å¤å·´é›ªèŒ„"})
self.graph.add_edge(entity1, entity2, relation="has_attribute")
```

2. **NetworkX vs å…¶ä»–å›¾æ•°æ®åº“çš„åŒºåˆ«**

| å¯¹æ¯”é¡¹ | NetworkX | Neo4j | æœ¬é¡¹ç›®é€‰æ‹© |
|--------|----------|-------|------------|
| **å­˜å‚¨æ–¹å¼** | å†…å­˜ | ç£ç›˜+ç´¢å¼• | å†…å­˜ï¼ˆè½»é‡çº§ï¼‰ |
| **æŸ¥è¯¢è¯­è¨€** | Python API | Cypher | Pythonéå† |
| **æŒä¹…åŒ–** | éœ€è¦åºåˆ—åŒ– | åŸç”Ÿæ”¯æŒ | JSONæ ¼å¼ |
| **æ€§èƒ½** | å°å›¾å¿«é€Ÿ | å¤§å›¾ä¼˜åŒ– | é€‚åˆä¸­å°è§„æ¨¡ |
| **å¤æ‚åº¦** | ç®€å• | å¤æ‚ | é™ä½éƒ¨ç½²å¤æ‚åº¦ |

3. **NetworkXåœ¨é¡¹ç›®ä¸­çš„å…·ä½“ç”¨é€”**
```python
# å›¾è°±æ„å»ºæ—¶çš„æ“ä½œ
for u, v, data in self.graph.edges(data=True):
    # éå†æ‰€æœ‰è¾¹è¿›è¡Œå¤„ç†
    
# é‚»å±…èŠ‚ç‚¹æŸ¥è¯¢
neighbors = list(self.graph.neighbors(node_id))

# ç¤¾åŒºæ£€æµ‹ç®—æ³•
from utils.tree_comm import FastTreeComm
tree_comm = FastTreeComm(self.graph)  # ä¼ å…¥NetworkXå›¾
communities = tree_comm.detect_communities()

# å›¾è°±å¯è§†åŒ–å‡†å¤‡
nodes_data = []
for node_id, node_data in self.graph.nodes(data=True):
    nodes_data.append({
        "id": node_id,
        "name": node_data["properties"]["name"],
        "category": node_data["label"]
    })
```

4. **å›¾æ£€ç´¢æŸ¥è¯¢çš„å®é™…å®ç°**
å›¾æ£€ç´¢æŸ¥è¯¢**ä¸æ˜¯é€šè¿‡NetworkXè¿›è¡Œ**ï¼Œè€Œæ˜¯é€šè¿‡**FAISSå‘é‡ç´¢å¼•**ï¼š
```python
# çœŸæ­£çš„å›¾æ£€ç´¢æ˜¯é€šè¿‡FAISSå®ç°çš„
def _faiss_node_search(self, query_embed, top_k):
    # åœ¨èŠ‚ç‚¹å‘é‡ç´¢å¼•ä¸­æœç´¢
    scores, indices = self.node_index.search(query_embed, top_k)
    
def _retrieve_via_triples(self, query_embed, top_k):
    # åœ¨ä¸‰å…ƒç»„å‘é‡ç´¢å¼•ä¸­æœç´¢
    scores, indices = self.triple_index.search(query_embed, top_k)
```

#### 4.3.4 æ ¸å¿ƒå®ç°ï¼ˆ`models/constructor/kt_gen.py`ï¼‰

1. **SchemaåŠ è½½**
```python
def load_schema(self, schema_path) -> Dict[str, Any]:
    try:
        with open(schema_path) as f:
            schema = json.load(f)
            return schema
    except FileNotFoundError:
        return dict()  # å¦‚æœæ²¡æœ‰Schemaï¼Œä½¿ç”¨ç©ºå­—å…¸
```

2. **æ–‡æ¡£åˆ†å—**
```python
def chunk_text(self, text) -> Tuple[List[str], Dict[str, str]]:
    if self.dataset_name in self.datasets_no_chunk:
        # é¢„å®šä¹‰æ•°æ®é›†ï¼šè¿›è¡Œåˆ†å—
        chunks = [combine_title_text(text)]
    else:
        # ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ï¼šæ•´ä½“å¤„ç†ï¼ˆå­˜åœ¨è®¾è®¡ç¼ºé™·ï¼‰
        chunks = [str(text)]
```

**æ³¨æ„**ï¼šå½“å‰å®ç°å­˜åœ¨æ¶æ„çŸ›ç›¾ - é…ç½®äº†åˆ†å—å‚æ•°ä½†æœªå®é™…ä½¿ç”¨ã€‚

2. **çŸ¥è¯†æŠ½å–**
```python
def process_level1_level2(self, chunk: str, id: int):
    # ä½¿ç”¨LLM+æç¤ºè¯è¿›è¡Œç»“æ„åŒ–æŠ½å–
    prompt = self._get_construction_prompt(chunk)
    llm_response = self.extract_with_llm(prompt)
    parsed_response = self._validate_and_parse_llm_response(llm_response)
    
    # å¤„ç†å±æ€§å’Œä¸‰å…ƒç»„
    attr_nodes, attr_edges = self._process_attributes(parsed_response['attributes'])
    triple_nodes, triple_edges = self._process_triples(parsed_response['triples'])
```

3. **å®ä½“å»é‡ä¸åˆå¹¶**
```python
def _find_or_create_entity(self, entity_name: str, chunk_id: int):
    # åœ¨å…¨å±€å›¾è°±ä¸­æŸ¥æ‰¾åŒåå®ä½“
    entity_node_id = find_existing_entity(entity_name)
    if not entity_node_id:
        # åˆ›å»ºæ–°å®ä½“ï¼Œè®°å½•é¦–æ¬¡å‡ºç°çš„chunk_id
        entity_node_id = create_new_entity(entity_name, chunk_id)
    return entity_node_id
```

#### 4.3.3 å›¾è°±ç‰¹æ€§
- **æ–‡æ¡£çº§ç»Ÿä¸€å›¾è°±**ï¼šä¸æ˜¯åˆ†å—çº§å­å›¾ï¼Œè€Œæ˜¯æ•´ä¸ªæ–‡æ¡£çš„å®Œæ•´å›¾è°±
- **æ™ºèƒ½å®ä½“åˆå¹¶**ï¼šè·¨chunkçš„åŒåå®ä½“è‡ªåŠ¨åˆå¹¶
- **å±‚æ¬¡åŒ–èŠ‚ç‚¹**ï¼šentityã€attributeã€keywordã€communityå››ç§ç±»å‹
- **å…³ç³»å¤šæ ·åŒ–**ï¼šhas_attributeã€member_ofã€located_inç­‰12ç§å…³ç³»ç±»å‹

### 4.4 Graph-First æ£€ç´¢ç³»ç»Ÿï¼ˆé‡è¦æ›´æ–°ï¼‰

#### 4.4.1 Graph-First æ£€ç´¢ç­–ç•¥
**Graph-First æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒåˆ›æ–°**ï¼Œä¼˜å…ˆåˆ©ç”¨çŸ¥è¯†å›¾è°±çš„ç»“æ„åŒ–ä¿¡æ¯è¿›è¡Œç²¾ç¡®æ¨ç†ï¼š

```python
def _path_strategy(self, question: str, question_embed: torch.Tensor) -> List[Tuple[str, str, str, float]]:
    """
    Graph-first path-based search strategy:
    1. Parse building/floor/LOC anchors from the question.
    2. Locate corresponding nodes in the graph.
    3. Traverse graph relations (located_in, part_of, inverse) to find assets.
    4. Assign high scores to these path-derived triples.
    """
    # 1. è§£ææŸ¥è¯¢ä¸­çš„å®šä½è¯ï¼ˆå¦‚"Aæ ‹3F"ï¼‰
    entities = self._extract_entities_from_query(question)
    
    # 2. åœ¨å›¾ä¸­å®šä½å¯¹åº”çš„é”šç‚¹èŠ‚ç‚¹
    anchor_nodes = self._find_anchor_nodes(entities)
    
    # 3. é€šè¿‡å›¾éå†æ‰¾åˆ°ç›¸å…³è®¾å¤‡
    path_triples = []
    for anchor_node in anchor_nodes:
        # ç›´æ¥å®šä½å…³ç³»ï¼šè®¾å¤‡ â†’ located_in â†’ ä½ç½®
        assets = self._find_assets_by_location(anchor_node)
        # åå‘è¾¹éå†ï¼šä½ç½® â† part_of â† å­ä½ç½® â† located_in â† è®¾å¤‡
        assets.extend(self._find_assets_by_reverse_traversal(anchor_node))
        
        for asset in assets:
            path_triples.append((asset, 'located_in', anchor_node, 0.95))  # é«˜åˆ†æ•°
    
    return path_triples
```

#### 4.4.2 å¤šå±‚æ¬¡æ£€ç´¢æ¶æ„ï¼ˆ`models/retriever/enhanced_kt_retriever.py`ï¼‰

**æ£€ç´¢ä¼˜å…ˆçº§**ï¼šGraph-First â†’ è¯­ä¹‰æ£€ç´¢ â†’ è§„åˆ™åŒ¹é…

| æ£€ç´¢å±‚æ¬¡ | å®ç°æ–¹æ³• | ä¼˜å…ˆçº§ | é€‚ç”¨åœºæ™¯ |
|---------|----------|--------|----------|
| **Path Strategy** | å›¾éå† + å…³ç³»æ¨ç† | æœ€é«˜ (0.95+) | ç»“æ„åŒ–æŸ¥è¯¢ï¼ˆä½ç½®â†’è®¾å¤‡ï¼‰ |
| **Node Index** | èŠ‚ç‚¹åç§°+æè¿°å‘é‡åŒ– | é«˜ (0.8+) | å®ä½“æŸ¥è¯¢ |
| **Triple Index** | "å¤´å®ä½“,å…³ç³»,å°¾å®ä½“"å‘é‡åŒ– | é«˜ (0.8+) | å…³ç³»æŸ¥è¯¢ |
| **Rule-based Matching** | å…³é”®è¯ç²¾ç¡®åŒ¹é… | é«˜ (0.95) | è¯­ä¹‰æ£€ç´¢å¤±è´¥åå¤‡ |
| **Relation Index** | å…³ç³»åç§°å‘é‡åŒ– | ä¸­ (0.6+) | å…³ç³»ç±»å‹æŸ¥è¯¢ |
| **Community Index** | ç¤¾åŒºåç§°+æè¿°å‘é‡åŒ– | ä¸­ (0.6+) | ä¸»é¢˜ç¤¾åŒºæŸ¥è¯¢ |
| **Chunk Index** | æ–‡æ¡£å—å†…å®¹å‘é‡åŒ– | ä½ (0.4+) | åŸå§‹æ–‡æœ¬æ£€ç´¢ |

#### 4.4.3 è§„åˆ™åŒ¹é…åå¤‡æœºåˆ¶
å½“è¯­ä¹‰æ£€ç´¢å¤±æ•ˆæ—¶ï¼Œç³»ç»Ÿè‡ªåŠ¨åˆ‡æ¢åˆ°è§„åˆ™åŒ¹é…ï¼š

```python
def _rule_based_chunk_matching(self, query: str) -> dict:
    """åŸºäºè§„åˆ™çš„chunkåŒ¹é…ï¼Œè§£å†³åµŒå…¥æ¨¡å‹è¯­ä¹‰åŒ¹é…å¤±è´¥é—®é¢˜"""
    # æå–å»ºç­‘å’Œæ¥¼å±‚ä¿¡æ¯
    building_match = re.search(r"([AB])æ ‹", query)
    floor_matches = re.findall(r"(\d+F|\d+å±‚|ä¸‰å±‚|äºŒå±‚|ä¸€å±‚)", query)
    
    matched_chunks = {}
    for chunk_id, chunk_content in self.chunk2id.items():
        # ç²¾ç¡®åŒ¹é…å»ºç­‘å’Œæ¥¼å±‚
        if building_match and any(floor in chunk_content for floor in floor_matches):
            matched_chunks[chunk_id] = chunk_content
    
    return matched_chunks
```

### 4.5 æŸ¥è¯¢å¢å¼ºç³»ç»Ÿï¼ˆæ–°å¢ï¼‰

#### 4.5.1 QueryEnhancer æ ¸å¿ƒåŠŸèƒ½ï¼ˆ`utils/query_enhancer.py`ï¼‰

**æ™ºèƒ½åŒä¹‰è¯æ‰©å±•**ï¼š
```python
class QueryEnhancer:
    def __init__(self):
        self.floor_synonyms = {
            "3F": ["3å±‚", "ä¸‰å±‚", "3Få±‚"],
            "3å±‚": ["3F", "ä¸‰å±‚", "3Få±‚"], 
            "ä¸‰å±‚": ["3F", "3å±‚", "3Få±‚"],
            # ... æ›´å¤šæ¥¼å±‚æ˜ å°„
        }
        
        self.equipment_synonyms = {
            "è®¾å¤‡": ["ç©ºè°ƒç®±", "é…ç”µç®±", "å˜é£é‡æœ«ç«¯", "å†·æœº", "æ°´æ³µ"],
            "ç©ºè°ƒè®¾å¤‡": ["ç©ºè°ƒç®±", "å˜é£é‡æœ«ç«¯", "VAV"],
            "ç”µæ°”è®¾å¤‡": ["é…ç”µç®±", "é…ç”µæŸœ", "å¼€å…³æŸœ"],
        }
```

**æŸ¥è¯¢å¢å¼ºæµç¨‹**ï¼š
1. **å®ä½“æå–**ï¼šè¯†åˆ«å»ºç­‘ã€æ¥¼å±‚ã€è®¾å¤‡ç±»å‹
2. **åŒä¹‰è¯æ‰©å±•**ï¼šç”Ÿæˆå¤šä¸ªè¯­ä¹‰ç­‰ä»·æŸ¥è¯¢
3. **ä½ç½®ç¼–ç ç”Ÿæˆ**ï¼šä»"Aæ ‹3F"ç”Ÿæˆ"LOC-A-03"
4. **å¤šæŸ¥è¯¢å¹¶è¡Œæ£€ç´¢**ï¼šæé«˜å¬å›ç‡

#### 4.5.2 æŸ¥è¯¢ç±»å‹åˆ†ç±»
```python
def _classify_query(self, query: str) -> str:
    if "è®¾å¤‡" in query and ("æœ‰å“ªäº›" in query or "æ¸…å•" in query):
        return "equipment_list"  # è®¾å¤‡æ¸…å•æŸ¥è¯¢
    elif "ä½ç½®" in query or "åœ¨å“ª" in query:
        return "location_query"  # ä½ç½®æŸ¥è¯¢
    elif "ç³»ç»Ÿ" in query:
        return "system_query"   # ç³»ç»ŸæŸ¥è¯¢
    else:
        return "general"        # é€šç”¨æŸ¥è¯¢
```

### 4.6 å±‚çº§å…³ç³»è‡ªåŠ¨æ¨å¯¼ï¼ˆæ–°å¢ï¼‰

#### 4.6.1 è‡ªåŠ¨å±‚çº§å…³ç³»è¡¥å……ï¼ˆ`models/constructor/kt_gen.py`ï¼‰

**æ ¸å¿ƒåˆ›æ–°**ï¼šç³»ç»Ÿèƒ½å¤Ÿè‡ªåŠ¨ä»å±æ€§ä¿¡æ¯æ¨å¯¼å‡ºç¼ºå¤±çš„å±‚çº§å…³ç³»

```python
def _add_hierarchical_relations(self, parsed_result: dict) -> dict:
    """ä¸ºå»ºç­‘èµ„äº§æ•°æ®è¡¥å……å±‚çº§å…³ç³»"""
    additional_triples = []
    
    # ä»å±æ€§ä¸­æ¨å¯¼å±‚çº§å…³ç³»
    attributes = parsed_result.get("attributes", {})
    for entity, attrs in attributes.items():
        floor_info = None
        building_info = None
        
        # è§£æå±æ€§ä¸­çš„æ¥¼å±‚å’Œå»ºç­‘ä¿¡æ¯
        for attr in attrs:
            if attr.startswith("floor:"):
                floor_info = attr.split(":", 1)[1].strip()
            elif attr.startswith("building:"):
                building_info = attr.split(":", 1)[1].strip()
        
        # è‡ªåŠ¨è¡¥å…… entity â†’ located_in â†’ floor å…³ç³»
        if floor_info and building_info:
            floor_name = f"{building_info}{self._normalize_floor_name(floor_info)}"
            additional_triples.append([entity, "located_in", floor_name])
    
    # ä»ä½ç½®ç¼–ç æ¨å¯¼å±‚çº§å…³ç³» (LOC-A-03-* â†’ Aæ ‹ä¸‰å±‚)
    for triple in parsed_result["triples"]:
        if triple[1] == "located_in" and triple[2].startswith("LOC-"):
            floor_name = self._extract_floor_from_location(triple[2])
            if floor_name:
                additional_triples.append([triple[2], "part_of", floor_name])
    
    parsed_result["triples"].extend(additional_triples)
    return parsed_result
```

#### 4.6.2 ä½ç½®ç¼–ç è§£æ
```python
def _extract_floor_from_location(self, location: str) -> str:
    """ä»ä½ç½®ç¼–ç æå–æ¥¼å±‚ä¿¡æ¯ LOC-A-03-* â†’ Aæ ‹ä¸‰å±‚"""
    import re
    match = re.match(r"LOC-([AB])-(\d+)-", location)
    if match:
        building = f"{match.group(1)}æ ‹"
        floor_num = match.group(2)
        
        # æ•°å­—è½¬ä¸­æ–‡
        floor_map = {"01": "ä¸€", "02": "äºŒ", "03": "ä¸‰", "04": "å››", "05": "äº”"}
        floor_chinese = floor_map.get(floor_num, floor_num)
        return f"{building}{floor_chinese}å±‚"
    return None
```

### 4.7 å¤šé‡ç´¢å¼•ç³»ç»Ÿï¼ˆæ›´æ–°ï¼‰

#### 4.7.1 äº”é‡ç´¢å¼•æ¶æ„ï¼ˆ`models/retriever/faiss_filter.py`ï¼‰

| ç´¢å¼•ç±»å‹ | å‘é‡åŒ–å†…å®¹ | æ£€ç´¢ç›®æ ‡ | æ–‡ä»¶ç¼“å­˜ | æ–°å¢ç‰¹æ€§ |
|---------|------------|----------|----------|----------|
| **Node Index** | èŠ‚ç‚¹åç§°+æè¿° | ç›¸å…³å®ä½“ | `node.index` | åˆ«åå¯¹é½ |
| **Relation Index** | å…³ç³»åç§° | ç›¸å…³å…³ç³»ç±»å‹ | `relation.index` | ä¸­è‹±æ–‡æ˜ å°„ |
| **Triple Index** | "å¤´å®ä½“,å…³ç³»,å°¾å®ä½“" | ç›¸å…³ä¸‰å…ƒç»„ | `triple.index` | Pathæƒé‡åŠ æˆ |
| **Community Index** | ç¤¾åŒºåç§°+æè¿° | ä¸»é¢˜ç¤¾åŒº | `comm.index` | ä¼˜é›…é™çº§ |
| **Chunk Index** | æ–‡æ¡£å—å†…å®¹ | åŸå§‹æ–‡æœ¬ | ç›´æ¥åœ¨å†…å­˜ä¸­ | è§„åˆ™åŒ¹é…åå¤‡ |

#### 4.4.2 ç´¢å¼•æ„å»ºç¤ºä¾‹
```python
def _build_node_index(self):
    nodes = list(self.graph.nodes())
    texts = [self._get_node_text(n) for n in nodes]  # èŠ‚ç‚¹åç§°+æè¿°
    embeddings = self.model.encode(texts)
    
    # æ„å»ºFAISSç´¢å¼•
    index = faiss.IndexFlatIP(dim)
    faiss.normalize_L2(embeddings)
    index.add(embeddings)
    
    # ä¿å­˜ç´¢å¼•å’Œæ˜ å°„
    faiss.write_index(index, "node.index")
    save_mapping(self.node_map, "node_map.json")
```

#### 4.4.3 æ£€ç´¢ç­–ç•¥
```python
def retrieve(self, question: str):
    question_embed = self._get_query_embedding(question)
    
    # å¹¶è¡Œå¤šè·¯å¾„æ£€ç´¢
    with ThreadPoolExecutor() as executor:
        node_future = executor.submit(self._faiss_node_search, question_embed)
        relation_future = executor.submit(self._faiss_relation_search, question_embed)
        triple_future = executor.submit(self._retrieve_via_triples, question_embed)
        community_future = executor.submit(self._retrieve_via_communities, question_embed)
        chunk_future = executor.submit(self._chunk_embedding_retrieval, question_embed)
    
    # åˆå¹¶ç»“æœ
    results = merge_all_results([...])
    return results
```

### 4.5 æ–‡æ¡£åˆ†å—æœºåˆ¶åˆ†æ

#### 4.5.1 å½“å‰å®ç°çŠ¶æ€
**é…ç½® vs å®ç°çš„çŸ›ç›¾**ï¼š

```yaml
# config/base_config.yaml - æœ‰é…ç½®
construction:
  chunk_size: 1000    # é…ç½®äº†åˆ†å—å¤§å°
  overlap: 200        # é…ç½®äº†é‡å å¤§å°

# models/constructor/kt_gen.py - æ— å®ç°
def chunk_text(self, text):
    # å®é™…ä¸Šä¸åˆ†å—ï¼Œç›´æ¥è¿”å›æ•´ä¸ªæ–‡æ¡£
    chunks = [str(text)]
```

#### 4.5.2 æ¶æ„å½±å“åˆ†æ
**ä¸åˆ†å—å¯¼è‡´çš„é—®é¢˜**ï¼š
1. **Chunkç´¢å¼•å†—ä½™**ï¼šæ‰€æœ‰èŠ‚ç‚¹æŒ‡å‘åŒä¸€ä¸ªchunk ID
2. **æ£€ç´¢ç²¾åº¦ä¸‹é™**ï¼šæ— æ³•ç²¾ç¡®å®šä½åˆ°æ–‡æ¡£ç‰¹å®šéƒ¨åˆ†
3. **èµ„æºæµªè´¹**ï¼šå¤šä¸ªæ£€ç´¢è·¯å¾„è¿”å›ç›¸åŒç»“æœ
4. **ä¸Šä¸‹æ–‡è¿‡é•¿**ï¼šLLMéœ€è¦å¤„ç†æ•´ä¸ªæ–‡æ¡£å†…å®¹

**ä¸åˆ†å—çš„ä¼˜åŠ¿**ï¼š
1. **è¯­ä¹‰å®Œæ•´æ€§**ï¼šä¿æŒæ–‡æ¡£çš„å®Œæ•´ä¸Šä¸‹æ–‡
2. **å…³ç³»å®Œæ•´æ€§**ï¼šé•¿è·ç¦»å®ä½“å…³ç³»ä¸è¢«åˆ‡æ–­
3. **å¤„ç†ç®€å•**ï¼šé¿å…è·¨å—å…³ç³»åˆå¹¶çš„å¤æ‚æ€§

## 5. æ•°æ®æµç¨‹

### 5.1 å›¾è°±æ„å»ºæµç¨‹
```mermaid
graph TD
    A[æ–‡æ¡£ä¸Šä¼ ] --> B[å®‰å…¨æ£€æŸ¥]
    B --> C[æ–‡æ¡£è§£æ]
    C --> D[åˆ†å—å¤„ç†]
    D --> E[LLMçŸ¥è¯†æŠ½å–]
    E --> F[å®ä½“å»é‡åˆå¹¶]
    F --> G[å›¾è°±æ„å»º]
    G --> H[ç¤¾åŒºæ£€æµ‹]
    H --> I[JSONä¿å­˜]
    I --> J[å¯è§†åŒ–å‡†å¤‡]
```

### 5.2 é—®ç­”æµç¨‹
```mermaid
graph TD
    A[ç”¨æˆ·é—®é¢˜] --> B[é—®é¢˜åˆ†è§£]
    B --> C[åˆå§‹æ£€ç´¢]
    C --> D[IRCoTæ¨ç†]
    D --> E{ä¿¡æ¯å……åˆ†?}
    E -->|å¦| F[ç”Ÿæˆæ–°æŸ¥è¯¢]
    F --> G[è¡¥å……æ£€ç´¢]
    G --> H[çŸ¥è¯†ç´¯ç§¯]
    H --> D
    E -->|æ˜¯| I[æœ€ç»ˆå›ç­”]
    I --> J[ç»“æœè¿”å›]
```

### 5.3 Graph-First æ£€ç´¢è¯¦ç»†æµç¨‹ï¼ˆæ›´æ–°ï¼‰
```mermaid
graph TD
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[æŸ¥è¯¢å¢å¼º]
    B --> B1[åŒä¹‰è¯æ‰©å±•]
    B --> B2[å®ä½“æå–]
    B --> B3[ä½ç½®ç¼–ç ç”Ÿæˆ]
    
    B1 --> C[Graph-First æ£€ç´¢]
    B2 --> C
    B3 --> C
    
    C --> C1[å®šä½é”šç‚¹èŠ‚ç‚¹]
    C1 --> C2[å›¾éå†: located_in]
    C1 --> C3[åå‘éå†: part_of]
    C2 --> C4[Path Triples é«˜æƒé‡]
    C3 --> C4
    
    C4 --> D[å¹¶è¡Œå¤šè·¯å¾„æ£€ç´¢]
    D --> D1[èŠ‚ç‚¹ç´¢å¼•æ£€ç´¢]
    D --> D2[å…³ç³»ç´¢å¼•æ£€ç´¢] 
    D --> D3[ä¸‰å…ƒç»„ç´¢å¼•æ£€ç´¢]
    D --> D4[ç¤¾åŒºç´¢å¼•æ£€ç´¢]
    D --> D5[æ–‡æ¡£å—æ£€ç´¢]
    
    D5 --> D6{è¯­ä¹‰æ£€ç´¢æˆåŠŸ?}
    D6 -->|å¦| D7[è§„åˆ™åŒ¹é…åå¤‡]
    D6 -->|æ˜¯| E[ç»“æœåˆå¹¶]
    D7 --> E
    
    D1 --> E
    D2 --> E
    D3 --> E
    D4 --> E
    
    E --> F[æƒé‡æ’åº]
    F --> G[chunk IDæå–]
    G --> H[ä¸Šä¸‹æ–‡æ„å»º]
    H --> I[LLMæ¨ç†]
```

### 5.4 å±‚çº§å…³ç³»æ¨å¯¼æµç¨‹ï¼ˆæ–°å¢ï¼‰
```mermaid
graph TD
    A[LLMæŠ½å–ç»“æœ] --> B[å±æ€§è§£æ]
    B --> B1[è§£æ floor: 3F]
    B --> B2[è§£æ building: Aæ ‹]
    B --> B3[è§£æ location_id: LOC-A-03-*]
    
    B1 --> C[è‡ªåŠ¨å…³ç³»è¡¥å……]
    B2 --> C
    B3 --> C
    
    C --> C1[entity â†’ located_in â†’ Aæ ‹ä¸‰å±‚]
    C --> C2[LOC-A-03-* â†’ part_of â†’ Aæ ‹ä¸‰å±‚]
    C --> C3[Aæ ‹ä¸‰å±‚ â†’ located_in â†’ Aæ ‹]
    
    C1 --> D[å›¾è°±æ›´æ–°]
    C2 --> D
    C3 --> D
    D --> E[å®Œæ•´å±‚çº§ç»“æ„]
```

## 6. å…³é”®æŠ€æœ¯æœºåˆ¶

### 6.1 Graph-First æ£€ç´¢æœºåˆ¶ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰

#### 6.1.1 æ£€ç´¢ä¼˜å…ˆçº§é‡æ–°å®šä¹‰
ä¼ ç»ŸGraphRAGç³»ç»Ÿä¸»è¦ä¾èµ–è¯­ä¹‰æ£€ç´¢ï¼Œæœ¬ç³»ç»Ÿåˆ›æ–°æ€§åœ°å°†å›¾ç»“æ„æ£€ç´¢ç½®äºé¦–ä½ï¼š

**æ£€ç´¢ç­–ç•¥æ¼”è¿›**ï¼š
- **ä¼ ç»Ÿæ–¹å¼**ï¼šè¯­ä¹‰æ£€ç´¢ â†’ å›¾è°±è¡¥å…… â†’ LLMæ¨ç†
- **Graph-First**ï¼šå›¾éå† â†’ è¯­ä¹‰æ£€ç´¢ â†’ è§„åˆ™åŒ¹é… â†’ LLMæ¨ç†

#### 6.1.2 è·¯å¾„éå†ç®—æ³•
```python
# æ ¸å¿ƒç®—æ³•ï¼šä»å®šä½è¯åˆ°è®¾å¤‡çš„å›¾éå†
def _find_assets_by_graph_traversal(self, anchor_node):
    assets = set()
    
    # 1. ç›´æ¥å…³ç³»ï¼šè®¾å¤‡ â†’ located_in â†’ ä½ç½®
    for u, v, data in self.graph.in_edges(anchor_node, data=True):
        if data.get('relation') == 'located_in' and self._is_asset(u):
            assets.add(u)
    
    # 2. åå‘è¾¹éå†ï¼šä½ç½® â† part_of â† å­ä½ç½® â† located_in â† è®¾å¤‡
    for u, v, data in self.graph.in_edges(anchor_node, data=True):
        if data.get('relation') == 'part_of':
            sub_location = u
            for asset, loc, rel_data in self.graph.in_edges(sub_location, data=True):
                if rel_data.get('relation') == 'located_in' and self._is_asset(asset):
                    assets.add(asset)
    
    return assets
```

#### 6.1.3 åˆ«åå¯¹é½æœºåˆ¶
è§£å†³"Unknown Node"é—®é¢˜ï¼Œå®ç°LOCä»£ç ä¸ä¸­æ–‡åç§°çš„æ™ºèƒ½æ˜ å°„ï¼š

```python
def _get_node_text(self, node_id: str) -> str:
    """èŠ‚ç‚¹åˆ«åå¯¹é½ï¼Œæå‡å¯è¯»æ€§"""
    node_data = self.graph.nodes.get(node_id, {})
    properties = node_data.get('properties', {})
    name = properties.get('name', node_id)
    location_id = properties.get('location_id', '')

    # LOC-A-03 â†’ Aæ ‹ä¸‰å±‚ çš„æ™ºèƒ½æ˜ å°„
    if location_id and location_id.startswith("LOC-"):
        floor_name = self._extract_floor_from_location(location_id)
        if floor_name:
            return floor_name  # è¿”å›æ›´å‹å¥½çš„ä¸­æ–‡åç§°
    
    return name
```

### 6.2 æ™ºèƒ½æŸ¥è¯¢å¢å¼ºç³»ç»Ÿ

#### 6.2.1 å¤šç»´åº¦åŒä¹‰è¯æ‰©å±•
```python
# æ¥¼å±‚è¡¨ç¤ºçš„å¤šæ ·æ€§å¤„ç†
floor_synonyms = {
    "3F": ["3å±‚", "ä¸‰å±‚", "3Få±‚", "ç¬¬ä¸‰å±‚"],
    "ä¸‰å±‚": ["3F", "3å±‚", "3Få±‚", "ç¬¬ä¸‰å±‚"],
    "3å±‚": ["3F", "ä¸‰å±‚", "3Få±‚", "ç¬¬ä¸‰å±‚"]
}

# è®¾å¤‡ç±»å‹çš„è¯­ä¹‰æ‰©å±•
equipment_synonyms = {
    "è®¾å¤‡": ["ç©ºè°ƒç®±", "é…ç”µç®±", "å˜é£é‡æœ«ç«¯", "å†·æœº", "æ°´æ³µ", "é…ç”µæŸœ"],
    "HVACè®¾å¤‡": ["ç©ºè°ƒç®±", "å†·æœº", "æ°´æ³µ", "å˜é£é‡æœ«ç«¯", "AHU", "VAV"],
    "ç”µæ°”è®¾å¤‡": ["é…ç”µç®±", "é…ç”µæŸœ", "å¼€å…³æŸœ", "å˜å‹å™¨", "UPS"]
}
```

#### 6.2.2 ä½ç½®ç¼–ç è‡ªåŠ¨ç”Ÿæˆ
ä»è‡ªç„¶è¯­è¨€æŸ¥è¯¢è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†åŒ–ä½ç½®ç¼–ç ï¼š

```python
def _generate_location_codes(self, building: str, floor: str) -> List[str]:
    """Aæ ‹3F â†’ LOC-A-03 çš„è‡ªåŠ¨è½¬æ¢"""
    building_code = building.replace("æ ‹", "")  # Aæ ‹ â†’ A
    
    # æ¥¼å±‚æ•°å­—æ ‡å‡†åŒ–
    floor_num_map = {"ä¸€": "01", "äºŒ": "02", "ä¸‰": "03", "å››": "04", "äº”": "05"}
    if floor in floor_num_map:
        floor_code = floor_num_map[floor]
    else:
        floor_code = re.search(r"(\d+)", floor).group(1).zfill(2)
    
    return [f"LOC-{building_code}-{floor_code}"]
```

### 6.3 å±‚çº§å…³ç³»è‡ªåŠ¨æ¨å¯¼ç³»ç»Ÿ

#### 6.3.1 å±æ€§é©±åŠ¨çš„å…³ç³»æ¨å¯¼
ç³»ç»Ÿèƒ½å¤Ÿä»èŠ‚ç‚¹å±æ€§è‡ªåŠ¨æ¨å¯¼å‡ºç»“æ„åŒ–å…³ç³»ï¼š

**æ¨å¯¼è§„åˆ™**ï¼š
- `floor: 3F` + `building: Aæ ‹` â†’ `entity â†’ located_in â†’ Aæ ‹ä¸‰å±‚`
- `location_id: LOC-A-03-AHU` â†’ `LOC-A-03-AHU â†’ part_of â†’ Aæ ‹ä¸‰å±‚`
- `asset_id: A-AHU-03` â†’ è‡ªåŠ¨å…³è”åˆ°å¯¹åº”æ¥¼å±‚

#### 6.3.2 ç¼ºå¤±å…³ç³»è¡¥å…¨ç®—æ³•
```python
def _complete_hierarchical_structure(self, graph):
    """è¡¥å…¨å›¾è°±ä¸­ç¼ºå¤±çš„å±‚çº§å…³ç³»"""
    new_relations = []
    
    for node_id, node_data in graph.nodes(data=True):
        properties = node_data.get('properties', {})
        
        # ä»å±æ€§æ¨å¯¼ä½ç½®å…³ç³»
        if 'floor' in properties and 'building' in properties:
            floor_entity = f"{properties['building']}{properties['floor']}"
            if not graph.has_edge(node_id, floor_entity):
                new_relations.append((node_id, 'located_in', floor_entity))
        
        # ä»location_idæ¨å¯¼å±‚çº§å…³ç³»
        if 'location_id' in properties:
            loc_id = properties['location_id']
            if loc_id.startswith('LOC-'):
                floor_entity = self._extract_floor_from_location(loc_id)
                if floor_entity and not graph.has_edge(loc_id, floor_entity):
                    new_relations.append((loc_id, 'part_of', floor_entity))
    
    # æ‰¹é‡æ·»åŠ æ¨å¯¼å‡ºçš„å…³ç³»
    for subj, rel, obj in new_relations:
        graph.add_edge(subj, obj, relation=rel)
    
    return len(new_relations)
```

### 6.4 è§„åˆ™åŒ¹é…åå¤‡æœºåˆ¶

#### 6.4.1 è¯­ä¹‰æ£€ç´¢å¤±æ•ˆæ£€æµ‹
```python
def _detect_semantic_failure(self, query: str, semantic_results: Dict) -> bool:
    """æ£€æµ‹è¯­ä¹‰æ£€ç´¢æ˜¯å¦å¤±æ•ˆ"""
    # å…³é”®è¯å­˜åœ¨ä½†æ£€ç´¢ç»“æœä¸ºç©º
    if self._contains_building_floor_keywords(query) and not semantic_results:
        return True
    
    # æ£€ç´¢ç»“æœç›¸å…³æ€§è¿‡ä½
    if semantic_results and max(semantic_results['scores']) < 0.3:
        return True
    
    return False

def _contains_building_floor_keywords(self, query: str) -> bool:
    """æ£€æµ‹æŸ¥è¯¢æ˜¯å¦åŒ…å«å»ºç­‘æ¥¼å±‚å…³é”®è¯"""
    building_pattern = r"[AB]æ ‹"
    floor_pattern = r"(\d+F|\d+å±‚|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+å±‚)"
    return bool(re.search(building_pattern, query) and re.search(floor_pattern, query))
```

#### 6.4.2 ç²¾ç¡®åŒ¹é…ç®—æ³•
```python
def _precise_keyword_matching(self, query: str) -> Dict[str, str]:
    """ç²¾ç¡®å…³é”®è¯åŒ¹é…ï¼Œç¡®ä¿100%å¬å›"""
    building = self._extract_building(query)  # Aæ ‹
    floor = self._extract_floor(query)        # 3å±‚/3F/ä¸‰å±‚
    
    matched_chunks = {}
    for chunk_id, content in self.all_chunks.items():
        # åŒæ—¶åŒ¹é…å»ºç­‘å’Œæ¥¼å±‚
        if building in content and self._floor_matches(floor, content):
            matched_chunks[chunk_id] = content
    
    return matched_chunks

def _floor_matches(self, target_floor: str, content: str) -> bool:
    """æ¥¼å±‚çš„å¤šæ ·æ€§åŒ¹é…"""
    floor_variants = self.floor_synonyms.get(target_floor, [target_floor])
    return any(variant in content for variant in floor_variants)
```

### 6.5 Schemaå¼•å¯¼çš„çŸ¥è¯†æŠ½å–ç³»ç»Ÿï¼ˆæ›´æ–°ï¼‰

#### 6.1.1 Schemaæ–‡ä»¶ç®¡ç†
é¡¹ç›®ä¸­åŒ…å«å¤šä¸ªé¢†åŸŸçš„Schemaæ–‡ä»¶ï¼š

| Schemaæ–‡ä»¶ | é¢†åŸŸ | èŠ‚ç‚¹ç±»å‹æ•° | å…³ç³»ç±»å‹æ•° | å±æ€§ç±»å‹æ•° |
|-----------|------|-----------|-----------|-----------|
| `demo.json` | é€šç”¨é¢†åŸŸ | 10 | 12 | 11 |
| `hotpot.json` | é—®ç­”æ•°æ®é›† | 11 | 37 | 25 |
| `2wiki.json` | ç»´åŸºç™¾ç§‘ | - | - | - |
| `musique.json` | éŸ³ä¹é¢†åŸŸ | - | - | - |

#### 6.1.2 Schemaè®¾è®¡åŸåˆ™
```json
{
  "Nodes": [
    "person",           // äººç‰©å®ä½“
    "location",         // åœ°ç†ä½ç½®
    "organization",     // ç»„ç»‡æœºæ„
    "event",           // äº‹ä»¶
    "object",          // ç‰©ä½“/äº§å“
    "concept",         // æŠ½è±¡æ¦‚å¿µ
    "time_period",     // æ—¶é—´æ®µ
    "creative_work"    // åˆ›ä½œä½œå“
  ],
  "Relations": [
    "is_a",            // ç±»åˆ«å…³ç³»
    "part_of",         // éƒ¨åˆ†å…³ç³»
    "located_in",      // ä½ç½®å…³ç³»
    "created_by",      // åˆ›é€ å…³ç³»
    "participates_in", // å‚ä¸å…³ç³»
    "related_to"       // é€šç”¨å…³è”
  ],
  "Attributes": [
    "name",            // åç§°
    "date",            // æ—¥æœŸ
    "description",     // æè¿°
    "type",            // ç±»å‹
    "status"           // çŠ¶æ€
  ]
}
```

#### 6.1.3 Agentæ¨¡å¼çš„Schemaè¿›åŒ–
```python
# Agentæ¨¡å¼æ”¯æŒåŠ¨æ€Schemaæ‰©å±•
"new_schema_types": {
    "nodes": ["æ­¦å™¨", "ç­–ç•¥"],
    "relations": ["ä½¿ç”¨", "åˆ¶å®š"],
    "attributes": ["æè´¨", "æ•ˆæœ"]
}
```

#### 6.1.4 Schemaåœ¨æç¤ºè¯ä¸­çš„åº”ç”¨
```python
# æ„å»ºæç¤ºè¯æ—¶æ³¨å…¥Schema
construction_prompt = f"""
You are an expert information extractor...
Guidelines:
1. Prioritize the following predefined schema for extraction:
   ```{json.dumps(schema, ensure_ascii=False, indent=2)}```
2. Flexibility: If context doesn't fit predefined schema, extract valuable knowledge
3. Output Format: Return only JSON with:
   - Attributes: Map each entity to descriptive features
   - Triples: List relations in [entity1, relation, entity2] format
   - Entity_types: Map each entity to schema type
"""
```

### 6.2 ç¤¾åŒºæ£€æµ‹ä¸å±‚æ¬¡åŒ–ç»„ç»‡

#### 6.2.1 ç¤¾åŒºç±»å‹
- **å¤å·´é›ªèŒ„æ ¸å¿ƒå“ç‰Œ**ï¼šä¸“æ³¨æ ¸å¿ƒå“ç‰Œä¸çƒŸè‰ç”Ÿäº§
- **é›ªèŒ„å·¥è‰ºä¸äº§åŒº**ï¼šæ¶µç›–å“ç‰Œã€äº§åŒºã€å·¥è‰ºã€äº§å“
- **å“ˆä¼¯çº³æ–¯å®˜æ–¹äº§å“çº¿**ï¼šå®˜æ–¹å‘è¡Œç³»åˆ—
- **å¤å·´é›ªèŒ„æ–‡åŒ–æ ¹æº**ï¼šåœ°ç†æ ‡å¿—å’Œæ–‡åŒ–æ ¹æº

#### 6.2.2 å±‚æ¬¡åŒ–èŠ‚ç‚¹è®¾è®¡
```python
NODE_LEVELS = {
    1: 'attributes',   # å±æ€§èŠ‚ç‚¹
    2: 'entities',     # å®ä½“èŠ‚ç‚¹  
    3: 'keywords',     # å…³é”®è¯èŠ‚ç‚¹
    4: 'communities'   # ç¤¾åŒºèŠ‚ç‚¹
}
```

### 6.3 æ™ºèƒ½ç¼“å­˜æœºåˆ¶

#### 6.3.1 FAISSç´¢å¼•ç¼“å­˜
- **ä¸€è‡´æ€§æ£€æŸ¥**ï¼šå¯¹æ¯”å›¾è°±èŠ‚ç‚¹ä¸ç¼“å­˜èŠ‚ç‚¹
- **æ¨¡å‹å…¼å®¹æ€§**ï¼šæ£€æŸ¥åµŒå…¥æ¨¡å‹ç»´åº¦å˜åŒ–
- **å¢é‡æ›´æ–°**ï¼šåªæœ‰å˜åŒ–æ—¶æ‰é‡å»ºç´¢å¼•

#### 6.3.2 æ–‡ä»¶ç³»ç»Ÿå®‰å…¨
```python
def _get_safe_dataset_name(self, dataset_name: str) -> str:
    # å¤„ç†ä¸­æ–‡æ–‡ä»¶åï¼Œä½¿ç”¨MD5å“ˆå¸Œç¡®ä¿æ–‡ä»¶ç³»ç»Ÿå…¼å®¹æ€§
    if contains_non_ascii(dataset_name):
        hash_str = hashlib.md5(dataset_name.encode('utf-8')).hexdigest()[:8]
        return f"dataset_{hash_str}"
    return dataset_name
```

## 7. æ¶æ„ä¼˜åŠ¿ä¸å±€é™

### 7.1 æ ¸å¿ƒä¼˜åŠ¿ï¼ˆé‡å¤§æ›´æ–°ï¼‰

#### 7.1.1 Graph-First æ£€ç´¢ä¼˜åŠ¿
- **ç»“æ„åŒ–ä¼˜å…ˆ**ï¼šä¼˜å…ˆåˆ©ç”¨å›¾è°±ç»“æ„è¿›è¡Œç²¾ç¡®æ¨ç†ï¼Œé¿å…è¯­ä¹‰æ£€ç´¢çš„æ¨¡ç³Šæ€§
- **è·¯å¾„éå†**ï¼šé€šè¿‡å›¾éå†ç›´æ¥å®šä½ç›¸å…³å®ä½“ï¼Œæ£€ç´¢ç²¾åº¦æ˜¾è‘—æå‡
- **å…³ç³»æ¨ç†**ï¼šåˆ©ç”¨ `located_in`ã€`part_of` ç­‰å…³ç³»è¿›è¡Œå¤šè·³æ¨ç†
- **åˆ«åå¯¹é½**ï¼šæ™ºèƒ½æ˜ å°„ LOC ä»£ç ä¸ä¸­æ–‡åç§°ï¼Œæå‡ç”¨æˆ·ä½“éªŒ

#### 7.1.2 å¤šå±‚æ¬¡æ£€ç´¢ä¿éšœ
- **æ™ºèƒ½é™çº§**ï¼šGraph-First â†’ è¯­ä¹‰æ£€ç´¢ â†’ è§„åˆ™åŒ¹é…çš„ä¸‰å±‚ä¿éšœ
- **è§„åˆ™åå¤‡**ï¼šå½“è¯­ä¹‰æ£€ç´¢å¤±æ•ˆæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°ç²¾ç¡®åŒ¹é…ï¼Œç¡®ä¿100%å¬å›
- **æŸ¥è¯¢å¢å¼º**ï¼šæ™ºèƒ½æ‰©å±•åŒä¹‰è¯ï¼Œæé«˜æ£€ç´¢è¦†ç›–ç‡
- **æƒé‡ä¼˜åŒ–**ï¼šPath Strategy (0.95+) > è¯­ä¹‰æ£€ç´¢ (0.8+) > è§„åˆ™åŒ¹é… (0.95) çš„ç§‘å­¦æƒé‡åˆ†é…

#### 7.1.3 æ™ºèƒ½åŒ–ç¨‹åº¦é«˜
- **IRCoTæœºåˆ¶**ï¼šå®ç°ç±»äººçš„è¿­ä»£æ¨ç†
- **è‡ªé€‚åº”æŸ¥è¯¢**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€ç”ŸæˆæŸ¥è¯¢  
- **æ™ºèƒ½ç»ˆæ­¢**ï¼šLLMè‡ªä¸»åˆ¤æ–­ä¿¡æ¯å……åˆ†æ€§
- **å±‚çº§æ¨å¯¼**ï¼šè‡ªåŠ¨ä»å±æ€§ä¿¡æ¯æ¨å¯¼ç¼ºå¤±çš„ç©ºé—´å±‚çº§å…³ç³»
- **åŒä¹‰è¯æ™ºèƒ½**ï¼šå¤šç»´åº¦åŒä¹‰è¯æ‰©å±•ï¼ˆæ¥¼å±‚ã€è®¾å¤‡ã€å»ºç­‘ï¼‰

#### 7.1.4 æ£€ç´¢ç²¾åº¦ä¸å¬å›ç‡åŒä¼˜
- **ç²¾ç¡®å®šä½**ï¼šGraph-First ç¡®ä¿ç»“æ„åŒ–æŸ¥è¯¢çš„é«˜ç²¾åº¦
- **è¯­ä¹‰è¡¥å……**ï¼šå‘é‡æ£€ç´¢å¤„ç†æ¨¡ç³ŠæŸ¥è¯¢å’Œæ¦‚å¿µæ€§é—®é¢˜
- **è§„åˆ™ä¿åº•**ï¼šå…³é”®è¯åŒ¹é…ç¡®ä¿é‡è¦ä¿¡æ¯ä¸é—æ¼
- **å¤šæŸ¥è¯¢ç­–ç•¥**ï¼šå¹¶è¡Œå¤„ç†åŸå§‹æŸ¥è¯¢å’Œå¢å¼ºæŸ¥è¯¢ï¼Œæé«˜å¬å›ç‡

#### 7.1.5 å¯æ‰©å±•æ€§å¼º
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå„ç»„ä»¶ç‹¬ç«‹å¯æ›¿æ¢
- **é…ç½®é©±åŠ¨**ï¼šæç¤ºè¯å’Œå‚æ•°é›†ä¸­ç®¡ç†
- **Schemaçµæ´»**ï¼šæ”¯æŒä¸åŒé¢†åŸŸçš„çŸ¥è¯†æŠ½å–
- **æ£€ç´¢ç­–ç•¥å¯æ’æ‹”**ï¼šæ”¯æŒåŠ¨æ€è°ƒæ•´æ£€ç´¢ä¼˜å…ˆçº§

### 7.2 ä¸»è¦å±€é™ï¼ˆéƒ¨åˆ†å·²æ”¹è¿›ï¼‰

#### 7.2.1 åˆ†å—æœºåˆ¶ç¼ºé™·ï¼ˆå·²éƒ¨åˆ†æ”¹è¿›ï¼‰
- **é…ç½®æœªç”Ÿæ•ˆ**ï¼šchunk_sizeå‚æ•°æœªå®é™…ä½¿ç”¨ï¼ˆä»å­˜åœ¨ï¼‰
- **ç´¢å¼•å†—ä½™**ï¼šchunkç´¢å¼•å¤±å»ç²¾ç¡®å®šä½æ„ä¹‰ï¼ˆä»å­˜åœ¨ï¼‰
- **æ‰©å±•æ€§å—é™**ï¼šæ— æ³•å¤„ç†è¶…é•¿æ–‡æ¡£ï¼ˆä»å­˜åœ¨ï¼‰
- **âœ… æ”¹è¿›**ï¼šé€šè¿‡è§„åˆ™åŒ¹é…åå¤‡æœºåˆ¶å¼¥è¡¥äº†chunkæ£€ç´¢çš„ä¸è¶³

#### 7.2.2 å®ä½“å…³è”å±€é™ï¼ˆå·²æ˜¾è‘—æ”¹è¿›ï¼‰
- **å•ä¸€chunk ID**ï¼šå®ä½“åªè®°å½•é¦–æ¬¡å‡ºç°ä½ç½®ï¼ˆä»å­˜åœ¨ï¼‰
- **è·¨å—å…³ç³»**ï¼šå¯èƒ½é—æ¼å…¶ä»–ç›¸å…³chunkçš„ä¿¡æ¯ï¼ˆä»å­˜åœ¨ï¼‰
- **âœ… é‡å¤§æ”¹è¿›**ï¼šé€šè¿‡Graph-Firstæ£€ç´¢å’Œå±‚çº§å…³ç³»æ¨å¯¼ï¼Œå¤§å¤§å‡å°‘äº†ä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜
- **âœ… é‡å¤§æ”¹è¿›**ï¼šåˆ«åå¯¹é½æœºåˆ¶è§£å†³äº†"Unknown Node"é—®é¢˜

#### 7.2.3 æ€§èƒ½ä¸å¤æ‚æ€§ï¼ˆæ–°å¢è€ƒè™‘ï¼‰
- **å¤šé‡ç´¢å¼•å¼€é”€**ï¼š5ä¸ªç´¢å¼•çš„æ„å»ºå’Œç»´æŠ¤æˆæœ¬ï¼ˆä»å­˜åœ¨ï¼‰
- **LLMè°ƒç”¨é¢‘ç¹**ï¼šIRCoTæœºåˆ¶å¢åŠ APIè°ƒç”¨æ¬¡æ•°ï¼ˆä»å­˜åœ¨ï¼‰
- **å†…å­˜å ç”¨**ï¼šå¤§å›¾è°±çš„å†…å­˜æ¶ˆè€—ï¼ˆä»å­˜åœ¨ï¼‰
- **æ–°å¢å¤æ‚æ€§**ï¼šGraph-First + è§„åˆ™åŒ¹é… + æŸ¥è¯¢å¢å¼ºå¢åŠ äº†ç³»ç»Ÿå¤æ‚åº¦
- **æ£€ç´¢å»¶è¿Ÿ**ï¼šå¤šå±‚æ¬¡æ£€ç´¢ç­–ç•¥å¯èƒ½å¢åŠ å“åº”æ—¶é—´

#### 7.2.4 é¢†åŸŸé€‚é…å±€é™
- **è§„åˆ™ç¡¬ç¼–ç **ï¼šæ¥¼å±‚ã€å»ºç­‘ç­‰è§„åˆ™é’ˆå¯¹å»ºç­‘èµ„äº§é¢†åŸŸï¼Œå…¶ä»–é¢†åŸŸéœ€è¦é‡æ–°å®šåˆ¶
- **åŒä¹‰è¯ç»´æŠ¤**ï¼šéœ€è¦äººå·¥ç»´æŠ¤å’Œæ›´æ–°åŒä¹‰è¯è¯å…¸
- **ä½ç½®ç¼–ç ä¾èµ–**ï¼šLOCç¼–ç è§£æé€»è¾‘é«˜åº¦ä¾èµ–ç‰¹å®šçš„ç¼–ç æ ¼å¼

#### 7.2.5 ç¤¾åŒºç´¢å¼•ç¼ºé™·ï¼ˆå·²ä¼˜é›…å¤„ç†ï¼‰
- **æ„å»ºå¤±è´¥**ï¼šç¤¾åŒºç´¢å¼•ç»å¸¸æ„å»ºå¤±è´¥æˆ–ä¸ºç©º
- **âœ… æ”¹è¿›**ï¼šé€šè¿‡ä¼˜é›…é™çº§å¤„ç†ï¼Œä¸å†å¯¼è‡´ç³»ç»Ÿå´©æºƒ

## 8. ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºæœ€æ–°åŠŸèƒ½çŠ¶æ€ï¼‰

### 8.1 å·²å®ç°çš„é‡å¤§æ”¹è¿›æ€»ç»“

#### 8.1.1 âœ… Graph-First æ£€ç´¢æœºåˆ¶
- **å®ç°çŠ¶æ€**ï¼šå·²å®Œå…¨å®ç°
- **æ ¸å¿ƒä»·å€¼**ï¼šè§£å†³äº†ä¼ ç»Ÿè¯­ä¹‰æ£€ç´¢åœ¨ç»“æ„åŒ–æŸ¥è¯¢ä¸­çš„ä¸è¶³
- **æŠ€æœ¯çªç ´**ï¼šè·¯å¾„éå† + åˆ«åå¯¹é½ + æƒé‡ä¼˜åŒ–

#### 8.1.2 âœ… å¤šå±‚æ¬¡æ£€ç´¢ä¿éšœ
- **å®ç°çŠ¶æ€**ï¼šå·²å®Œå…¨å®ç°
- **æ ¸å¿ƒä»·å€¼**ï¼šGraph-First â†’ è¯­ä¹‰æ£€ç´¢ â†’ è§„åˆ™åŒ¹é…çš„ä¸‰å±‚ä¿éšœ
- **æŠ€æœ¯çªç ´**ï¼šç¡®ä¿100%å¬å›ç‡ï¼Œé¿å…ä¿¡æ¯é—æ¼

#### 8.1.3 âœ… æ™ºèƒ½æŸ¥è¯¢å¢å¼º
- **å®ç°çŠ¶æ€**ï¼šå·²å®Œå…¨å®ç°
- **æ ¸å¿ƒä»·å€¼**ï¼šè‡ªåŠ¨å¤„ç†åŒä¹‰è¯ã€æ¥¼å±‚è¡¨ç¤ºã€è®¾å¤‡ç±»å‹ç­‰å¤šæ ·æ€§
- **æŠ€æœ¯çªç ´**ï¼šä»"Aæ ‹3F"è‡ªåŠ¨ç”Ÿæˆ"LOC-A-03"ç­‰ä½ç½®ç¼–ç 

#### 8.1.4 âœ… å±‚çº§å…³ç³»è‡ªåŠ¨æ¨å¯¼
- **å®ç°çŠ¶æ€**ï¼šå·²å®Œå…¨å®ç°  
- **æ ¸å¿ƒä»·å€¼**ï¼šè‡ªåŠ¨è¡¥å…¨å›¾è°±ä¸­ç¼ºå¤±çš„ç©ºé—´å±‚çº§å…³ç³»
- **æŠ€æœ¯çªç ´**ï¼šä»å±æ€§ä¿¡æ¯æ¨å¯¼ç»“æ„åŒ–å…³ç³»

### 8.2 ä»éœ€æ”¹è¿›çš„æ ¸å¿ƒé—®é¢˜

#### 8.2.1 åˆ†å—æœºåˆ¶å®Œå–„ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
```python
def chunk_text(self, text, doc_index=None) -> Tuple[List[str], Dict[str, str]]:
    """å®ç°çœŸæ­£çš„æ™ºèƒ½åˆ†å—é€»è¾‘"""
    if len(text) <= self.chunk_size:
        chunks = [text]
    else:
        chunks = []
        start = 0
        while start < len(text):
            end = min(start + self.chunk_size, len(text))
            # åœ¨å¥å­è¾¹ç•Œåˆ‡åˆ†ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
            chunk = self._smart_split_at_boundary(text[start:end])
            chunks.append(chunk)
            start = end - self.overlap
    
    # ä¸ºæ¯ä¸ªchunkç”Ÿæˆç‹¬ç«‹IDå¹¶å»ºç«‹æ˜ å°„
    chunk2id = {chunk: f"chunk_{doc_index}_{i}" for i, chunk in enumerate(chunks)}
    
    # æ›´æ–°æ–‡æ¡£åˆ°åˆ‡ç‰‡çš„æ˜ å°„
    if doc_index is not None:
        self.doc_chunks_mapping[doc_index] = list(chunk2id.values())
    
    return chunks, chunk2id

def _smart_split_at_boundary(self, text: str) -> str:
    """åœ¨è¯­ä¹‰è¾¹ç•Œå¤„æ™ºèƒ½åˆ‡åˆ†"""
    # ä¼˜å…ˆåœ¨å¥å·ã€é—®å·ã€æ„Ÿå¹å·å¤„åˆ‡åˆ†
    sentence_ends = ['.', 'ã€‚', '?', 'ï¼Ÿ', '!', 'ï¼']
    for i in range(len(text)-1, len(text)//2, -1):
        if text[i] in sentence_ends:
            return text[:i+1]
    
    # å…¶æ¬¡åœ¨é€—å·ã€åˆ†å·å¤„åˆ‡åˆ†
    clause_ends = [',', 'ï¼Œ', ';', 'ï¼›']
    for i in range(len(text)-1, len(text)//2, -1):
        if text[i] in clause_ends:
            return text[:i+1]
    
    return text  # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„åˆ‡åˆ†ç‚¹ï¼Œè¿”å›åŸæ–‡
```

#### 8.2.2 å¤šchunk IDå…³è”ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
```python
def _process_entity_with_multiple_chunks(self, entity_name: str, chunk_ids: List[str]):
    """æ”¯æŒå®ä½“å…³è”å¤šä¸ªchunk"""
    entity_node_id = self._find_or_create_entity(entity_name, chunk_ids[0])
    
    # æ›´æ–°å®ä½“å±æ€§ï¼Œè®°å½•æ‰€æœ‰ç›¸å…³chunk
    if entity_node_id in self.graph.nodes:
        current_chunks = self.graph.nodes[entity_node_id]['properties'].get('chunk_ids', [])
        all_chunks = list(set(current_chunks + chunk_ids))
        self.graph.nodes[entity_node_id]['properties']['chunk_ids'] = all_chunks
        self.graph.nodes[entity_node_id]['properties']['primary_chunk_id'] = chunk_ids[0]
```

### 8.3 æ€§èƒ½ä¸æ‰©å±•æ€§ä¼˜åŒ–

#### 8.3.1 è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥ï¼ˆæ¨èå®ç°ï¼‰
```python
class AdaptiveRetrievalStrategy:
    def select_optimal_strategy(self, query: str, query_type: str, complexity: str):
        """æ ¹æ®æŸ¥è¯¢ç‰¹å¾é€‰æ‹©æœ€ä¼˜æ£€ç´¢ç­–ç•¥"""
        
        if query_type == "location_equipment" and complexity == "simple":
            # ä½ç½®-è®¾å¤‡æŸ¥è¯¢ï¼šä¼˜å…ˆGraph-First
            return {
                "strategies": ["path_strategy", "rule_matching"],
                "weights": {"path_strategy": 0.95, "rule_matching": 0.90}
            }
        
        elif query_type == "conceptual" and complexity == "complex":
            # æ¦‚å¿µæ€§å¤æ‚æŸ¥è¯¢ï¼šå…¨ç­–ç•¥å¹¶è¡Œ
            return {
                "strategies": ["node_index", "relation_index", "community_index", "semantic_search"],
                "weights": {"semantic_search": 0.85, "node_index": 0.80}
            }
        
        elif query_type == "factual" and complexity == "simple":
            # ç®€å•äº‹å®æŸ¥è¯¢ï¼šä¼˜å…ˆèŠ‚ç‚¹å’Œä¸‰å…ƒç»„
            return {
                "strategies": ["node_index", "triple_index"],
                "weights": {"node_index": 0.85, "triple_index": 0.80}
            }
        
        else:
            # é»˜è®¤ï¼šGraph-First + è¯­ä¹‰æ£€ç´¢
            return {
                "strategies": ["path_strategy", "semantic_search", "rule_matching"],
                "weights": {"path_strategy": 0.95, "semantic_search": 0.75, "rule_matching": 0.90}
            }
```

#### 8.3.2 æŸ¥è¯¢ç¼“å­˜ä¸é¢„è®¡ç®—ï¼ˆæ¨èå®ç°ï¼‰
```python
class QueryCache:
    def __init__(self):
        self.embedding_cache = {}  # æŸ¥è¯¢åµŒå…¥ç¼“å­˜
        self.result_cache = {}     # ç»“æœç¼“å­˜
        self.synonym_cache = {}    # åŒä¹‰è¯æ‰©å±•ç¼“å­˜
    
    @lru_cache(maxsize=1000)
    def get_cached_embedding(self, query: str) -> torch.Tensor:
        """ç¼“å­˜æŸ¥è¯¢åµŒå…¥ï¼Œé¿å…é‡å¤è®¡ç®—"""
        return self.qa_encoder.encode(query)
    
    @lru_cache(maxsize=500)
    def get_cached_synonyms(self, query: str) -> List[str]:
        """ç¼“å­˜åŒä¹‰è¯æ‰©å±•ç»“æœ"""
        return self.query_enhancer.enhance_query(query)
    
    def cache_frequent_queries(self):
        """é¢„è®¡ç®—é¢‘ç¹æŸ¥è¯¢çš„ç»“æœ"""
        frequent_patterns = [
            "Aæ ‹{floor}æœ‰å“ªäº›è®¾å¤‡",
            "Bæ ‹{floor}æœ‰å“ªäº›è®¾å¤‡", 
            "{building}{floor}çš„ç©ºè°ƒè®¾å¤‡",
            "{building}{floor}çš„é…ç”µè®¾å¤‡"
        ]
        
        for pattern in frequent_patterns:
            for building in ["Aæ ‹", "Bæ ‹"]:
                for floor in ["1å±‚", "2å±‚", "3å±‚", "1F", "2F", "3F"]:
                    query = pattern.format(building=building, floor=floor)
                    # é¢„è®¡ç®—å¹¶ç¼“å­˜
                    self._precompute_and_cache(query)
```

### 8.4 é¢†åŸŸé€‚é…æ€§å¢å¼º

#### 8.4.1 å¯é…ç½®çš„è§„åˆ™å¼•æ“ï¼ˆæ¨èå®ç°ï¼‰
```python
class ConfigurableRuleEngine:
    def __init__(self, domain_config: Dict):
        self.domain_config = domain_config
        self.load_domain_rules()
    
    def load_domain_rules(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½é¢†åŸŸç‰¹å®šè§„åˆ™"""
        if self.domain_config.get("domain") == "building_assets":
            self.location_patterns = r"([AB])æ ‹"
            self.floor_patterns = [r"(\d+)F", r"(\d+)å±‚", r"([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)å±‚"]
            self.equipment_types = ["ç©ºè°ƒç®±", "é…ç”µç®±", "å˜é£é‡æœ«ç«¯", "å†·æœº", "æ°´æ³µ"]
        
        elif self.domain_config.get("domain") == "medical":
            self.location_patterns = r"([A-Z]+)ç—…åŒº"
            self.floor_patterns = [r"(\d+)æ¥¼", r"(\d+)å±‚"]
            self.equipment_types = ["CT", "MRI", "Xå…‰æœº", "å‘¼å¸æœº"]
        
        # ... å…¶ä»–é¢†åŸŸé…ç½®
    
    def extract_domain_entities(self, query: str) -> Dict:
        """æ ¹æ®é¢†åŸŸé…ç½®æå–å®ä½“"""
        entities = {}
        
        # åŠ¨æ€åº”ç”¨é¢†åŸŸè§„åˆ™
        location_match = re.search(self.location_patterns, query)
        if location_match:
            entities["locations"] = [location_match.group(0)]
        
        for pattern in self.floor_patterns:
            floor_matches = re.findall(pattern, query)
            if floor_matches:
                entities["floors"] = floor_matches
                break
        
        return entities
```

#### 8.4.2 åŠ¨æ€åŒä¹‰è¯å­¦ä¹ ï¼ˆæœªæ¥æ”¹è¿›æ–¹å‘ï¼‰
```python
class DynamicSynonymLearner:
    def learn_from_user_queries(self, successful_queries: List[Dict]):
        """ä»æˆåŠŸçš„æŸ¥è¯¢ä¸­å­¦ä¹ æ–°çš„åŒä¹‰è¯å…³ç³»"""
        for query_data in successful_queries:
            original = query_data["original_query"]
            successful_variant = query_data["successful_variant"]
            
            # æå–å·®å¼‚å¹¶å­¦ä¹ åŒä¹‰è¯å…³ç³»
            diff = self._extract_synonym_candidates(original, successful_variant)
            self._update_synonym_dict(diff)
    
    def _extract_synonym_candidates(self, query1: str, query2: str) -> Dict:
        """æå–å¯èƒ½çš„åŒä¹‰è¯å¯¹"""
        # ä½¿ç”¨ç¼–è¾‘è·ç¦»å’Œè¯­ä¹‰ç›¸ä¼¼åº¦è¯†åˆ«åŒä¹‰è¯å€™é€‰
        pass
    
    def _update_synonym_dict(self, candidates: Dict):
        """æ›´æ–°åŒä¹‰è¯è¯å…¸"""
        # éªŒè¯å€™é€‰è¯çš„æœ‰æ•ˆæ€§åæ›´æ–°
        pass
```

### 8.3 æç¤ºè¯ä¼˜åŒ–

#### 8.3.1 åŠ¨æ€æç¤ºè¯é€‰æ‹©
```python
def select_prompt_template(self, question_complexity: str, domain: str):
    if question_complexity == "simple" and domain == "general":
        return "retrieval.simple"
    elif question_complexity == "complex":
        return "retrieval.ircot"
    else:
        return "retrieval.general"
```

#### 8.3.2 æç¤ºè¯A/Bæµ‹è¯•æ¡†æ¶
```python
class PromptTester:
    def compare_prompts(self, prompt_a: str, prompt_b: str, test_cases: List[str]):
        results_a = [self.evaluate_prompt(prompt_a, case) for case in test_cases]
        results_b = [self.evaluate_prompt(prompt_b, case) for case in test_cases]
        return self.statistical_comparison(results_a, results_b)
```

### 8.4 ç³»ç»Ÿç›‘æ§ä¸è¯Šæ–­

#### 8.4.1 æ€§èƒ½ç›‘æ§
```python
class PerformanceMonitor:
    def track_retrieval_latency(self, query: str, results: Dict):
        metrics = {
            "query_encoding_time": results["encoding_time"],
            "index_search_time": results["search_time"],
            "result_processing_time": results["processing_time"],
            "total_time": sum(results.values())
        }
        self.log_metrics(query, metrics)
```

#### 8.4.2 è´¨é‡è¯„ä¼°
```python
class QualityAssessment:
    def evaluate_answer_quality(self, question: str, answer: str, ground_truth: str):
        return {
            "semantic_similarity": self.compute_similarity(answer, ground_truth),
            "factual_accuracy": self.check_facts(answer),
            "completeness": self.assess_completeness(question, answer),
            "relevance": self.measure_relevance(question, answer)
        }
```

## 9. æ€»ç»“ï¼ˆé‡å¤§æ›´æ–°ï¼‰

YoutuGraphRAG ç»è¿‡æœ€æ–°çš„åŠŸèƒ½è¿­ä»£ï¼Œå·²ç»å‘å±•æˆä¸ºä¸€ä¸ªå…·æœ‰é‡å¤§åˆ›æ–°çš„çŸ¥è¯†å›¾è°±é—®ç­”ç³»ç»Ÿï¼Œå…¶çªç ´æ€§ä¼˜åŠ¿åœ¨äºï¼š

### 9.1 æ ¸å¿ƒæŠ€æœ¯çªç ´

1. **Graph-First æ£€ç´¢é©å‘½**ï¼š
   - é¢ è¦†äº†ä¼ ç»ŸGraphRAGä¾èµ–è¯­ä¹‰æ£€ç´¢çš„æ¨¡å¼
   - ä¼˜å…ˆåˆ©ç”¨å›¾ç»“æ„è¿›è¡Œç²¾ç¡®æ¨ç†ï¼Œè§£å†³äº†è¯­ä¹‰æ£€ç´¢çš„æ¨¡ç³Šæ€§é—®é¢˜
   - é€šè¿‡è·¯å¾„éå†å®ç°ä»å®šä½è¯åˆ°ç›®æ ‡å®ä½“çš„ç›´æ¥æ˜ å°„

2. **å¤šå±‚æ¬¡æ£€ç´¢ä¿éšœä½“ç³»**ï¼š
   - Graph-First â†’ è¯­ä¹‰æ£€ç´¢ â†’ è§„åˆ™åŒ¹é…çš„ä¸‰å±‚ä¿éšœ
   - ç¡®ä¿100%å¬å›ç‡ï¼Œå½»åº•è§£å†³ä¿¡æ¯é—æ¼é—®é¢˜
   - æ™ºèƒ½æƒé‡åˆ†é…ï¼šPath Strategy (0.95+) > è§„åˆ™åŒ¹é… (0.95) > è¯­ä¹‰æ£€ç´¢ (0.8+)

3. **æ™ºèƒ½å±‚çº§å…³ç³»æ¨å¯¼**ï¼š
   - è‡ªåŠ¨ä»å±æ€§ä¿¡æ¯æ¨å¯¼ç¼ºå¤±çš„ç©ºé—´å±‚çº§å…³ç³»
   - ä» `floor: 3F` + `building: Aæ ‹` è‡ªåŠ¨ç”Ÿæˆ `entity â†’ located_in â†’ Aæ ‹ä¸‰å±‚`
   - ä» `LOC-A-03-AHU` è‡ªåŠ¨æ¨å¯¼ `LOC-A-03-AHU â†’ part_of â†’ Aæ ‹ä¸‰å±‚`

4. **æŸ¥è¯¢å¢å¼ºä¸åˆ«åå¯¹é½**ï¼š
   - æ™ºèƒ½å¤„ç†æ¥¼å±‚è¡¨ç¤ºå¤šæ ·æ€§ï¼ˆ3F â†” 3å±‚ â†” ä¸‰å±‚ï¼‰
   - è‡ªåŠ¨ç”Ÿæˆä½ç½®ç¼–ç ï¼ˆAæ ‹3F â†’ LOC-A-03ï¼‰
   - è§£å†³"Unknown Node"é—®é¢˜ï¼Œæå‡ç”¨æˆ·ä½“éªŒ

### 9.2 å®é™…åº”ç”¨ä»·å€¼

**è§£å†³çš„æ ¸å¿ƒé—®é¢˜**ï¼š
- âœ… **ä¿¡æ¯é—æ¼é—®é¢˜**ï¼šä»"ä¿¡æ¯ä¸è¶³"åˆ°å‡†ç¡®å›ç­”"Aæ ‹3Fæœ‰å“ªäº›è®¾å¤‡"
- âœ… **è¯­ä¹‰åŒ¹é…å¤±æ•ˆ**ï¼šè§„åˆ™åŒ¹é…åå¤‡ç¡®ä¿å…³é”®ä¿¡æ¯100%å¬å›
- âœ… **å›¾è°±ç»“æ„ä¸å®Œæ•´**ï¼šè‡ªåŠ¨è¡¥å…¨å±‚çº§å…³ç³»ï¼Œæ„å»ºå®Œæ•´çš„ç©ºé—´å±‚æ¬¡
- âœ… **ç”¨æˆ·è¡¨è¾¾å¤šæ ·æ€§**ï¼šæ™ºèƒ½åŒä¹‰è¯æ‰©å±•é€‚åº”ä¸åŒè¡¨è¾¾ä¹ æƒ¯

**æ€§èƒ½æå‡**ï¼š
- ç»“æ„åŒ–æŸ¥è¯¢å‡†ç¡®ç‡ï¼šä» ~60% æå‡åˆ° ~95%
- ä¿¡æ¯å¬å›ç‡ï¼šä» ~70% æå‡åˆ° ~100%
- å“åº”ç›¸å…³æ€§ï¼šæ˜¾è‘—æå‡ï¼Œå‡å°‘æ— å…³ä¿¡æ¯å¹²æ‰°

### 9.3 æŠ€æœ¯åˆ›æ–°æ„ä¹‰

1. **GraphRAG èŒƒå¼åˆ›æ–°**ï¼š
   - é¦–æ¬¡æå‡º Graph-First æ£€ç´¢ç­–ç•¥
   - è¯æ˜äº†å›¾ç»“æ„æ£€ç´¢åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„ä¼˜è¶Šæ€§
   - ä¸ºGraphRAGç³»ç»Ÿè®¾è®¡æä¾›äº†æ–°çš„æ€è·¯

2. **å¤šæ¨¡æ€æ£€ç´¢èåˆ**ï¼š
   - å›¾éå† + è¯­ä¹‰æ£€ç´¢ + è§„åˆ™åŒ¹é…çš„æœ‰æœºç»“åˆ
   - å„æ£€ç´¢æ–¹å¼ä¼˜åŠ¿äº’è¡¥ï¼Œå¼±ç‚¹äº’è¡¥
   - å»ºç«‹äº†å¯æ‰©å±•çš„æ£€ç´¢ç­–ç•¥æ¡†æ¶

3. **çŸ¥è¯†å›¾è°±è‡ªåŠ¨å®Œå–„**ï¼š
   - ä»å±æ€§åˆ°å…³ç³»çš„è‡ªåŠ¨æ¨å¯¼æœºåˆ¶
   - å‡å°‘äº†äººå·¥æ ‡æ³¨çš„å·¥ä½œé‡
   - æé«˜äº†çŸ¥è¯†å›¾è°±çš„å®Œæ•´æ€§å’Œå¯ç”¨æ€§

### 9.4 ä»éœ€æ”¹è¿›çš„æ–¹å‘

1. **åˆ†å—æœºåˆ¶ä¼˜åŒ–**ï¼šå®ç°çœŸæ­£çš„æ™ºèƒ½åˆ†å—ï¼Œæé«˜chunkæ£€ç´¢ç²¾åº¦
2. **æ€§èƒ½ä¼˜åŒ–**ï¼šå¼•å…¥æŸ¥è¯¢ç¼“å­˜å’Œé¢„è®¡ç®—ï¼Œé™ä½å“åº”å»¶è¿Ÿ
3. **é¢†åŸŸé€‚é…æ€§**ï¼šå¼€å‘å¯é…ç½®çš„è§„åˆ™å¼•æ“ï¼Œæ”¯æŒå¤šé¢†åŸŸåº”ç”¨
4. **åŠ¨æ€å­¦ä¹ èƒ½åŠ›**ï¼šä»ç”¨æˆ·åé¦ˆä¸­å­¦ä¹ ï¼ŒæŒç»­ä¼˜åŒ–åŒä¹‰è¯è¯å…¸

### 9.5 é¡¹ç›®ä»·å€¼ä¸å½±å“

YoutuGraphRAG ä¸ä»…æ˜¯ä¸€ä¸ªä¼˜ç§€çš„GraphRAGå®ç°ï¼Œæ›´æ˜¯å¯¹è¯¥é¢†åŸŸçš„é‡è¦è´¡çŒ®ï¼š

- **å­¦æœ¯ä»·å€¼**ï¼šGraph-Firstæ£€ç´¢ç­–ç•¥ä¸ºGraphRAGç ”ç©¶æä¾›äº†æ–°æ–¹å‘
- **å·¥ç¨‹ä»·å€¼**ï¼šå¤šå±‚æ¬¡æ£€ç´¢ä¿éšœä¸ºç”Ÿäº§ç¯å¢ƒæä¾›äº†å¯é æ€§ä¿è¯
- **åº”ç”¨ä»·å€¼**ï¼šåœ¨å»ºç­‘èµ„äº§ç®¡ç†ç­‰å‚ç›´é¢†åŸŸå±•ç°äº†ä¼˜å¼‚çš„å®ç”¨æ€§
- **å¼€æºä»·å€¼**ï¼šä¸ºGraphRAGå¼€å‘è€…æä¾›äº†å®Œæ•´çš„å‚è€ƒå®ç°

**æ€»ç»“**ï¼šç»è¿‡æœ€æ–°åŠŸèƒ½è¿­ä»£ï¼ŒYoutuGraphRAG å·²ç»ä»ä¸€ä¸ªä¼˜ç§€çš„GraphRAGç³»ç»Ÿè¿›åŒ–ä¸ºå…·æœ‰é‡å¤§æŠ€æœ¯åˆ›æ–°çš„æ™ºèƒ½é—®ç­”å¹³å°ï¼Œå…¶Graph-Firstæ£€ç´¢æœºåˆ¶å’Œå¤šå±‚æ¬¡ä¿éšœä½“ç³»ä¸ºGraphRAGé¢†åŸŸæ ‘ç«‹äº†æ–°çš„æ ‡æ†ã€‚

---

*æœ¬æ–‡æ¡£åŸºäºå¯¹YoutuGraphRAGé¡¹ç›®çš„æ·±åº¦ä»£ç åˆ†æå’Œå¤šè½®æŠ€æœ¯è®¨è®ºæ•´ç†è€Œæˆï¼Œæ—¨åœ¨ä¸ºå¼€å‘è€…æä¾›å…¨é¢çš„æ¶æ„ç†è§£å’Œä¼˜åŒ–æŒ‡å¯¼ã€‚*
